# -*- coding: utf-8 -*-
"""Data_input.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TCINP7JJx975av20YL-6IjT5h5DN1ed0
"""

!pip install boto3

import boto3

from datetime import datetime
import pandas as pd
import time
import json
import boto3


# This generated a client based on server and region name
def gen_client(ser, reg):
  session = boto3.Session(aws_access_key_id="AKIAQ34KZBRTLZ7CB6IL" ,aws_secret_access_key="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")
  return session.client(ser, region_name=reg)

# Reading the file and returning a dataframe
def get_data(filename, f_type):
    if f_type == 'csv':
        #reading csv
        df = pd.read_csv(filename)
    elif f_type == 'excel':
        #reading excel
        df = pd.read_excel(filename)
    else:
        print('Incorrect File Type')
    return df


# code to prepare data to send to kinesis client
def send_kinesis(client, stream_name, shard_count, df):
    
    # len_rows = length of rows of input data
    # len_columns = length of columns of input data
    # C_bytes = Bytes count
    # shard_counter = shard counter
    # sendKinesis = 1 if we have to send the batch of data, 0 if we do not have to send the data


    combine_rows = []
    len_rows = len(df.axes[0])
    len_columns = rows = len(df.axes[1])
    C_bytes = 0
    rc = 0
    sendKinesis = 0    
    shard_counter = 1
    

    #Iterating over all the rows in the dataframe
    
    for _, row in df.iterrows(): 
        encodedValues = row.to_json().encode('utf-8')
        #encodedValues=json.dumps(row1).encode('utf-8')

        #creating a dictionary (Hashmap) of the data 
        kinesisRecord = {
            "Data": encodedValues, # encoded data
            "PartitionKey": str(shard_counter) # Kinesis shard number to be used with the batch
        }


        combine_rows.append(kinesisRecord)
        stringBytes = len(str(row).encode('utf-8'))
        C_bytes = C_bytes + stringBytes

        # conditions to send the data

        # if the len of dictionary is 15
        if len(combine_rows) == 15:
            sendKinesis = 1        

        # if we reach the last record
        if rc == len_rows - 1:
            sendKinesis = 1

        #if the byte size is greater than 20000
        if C_bytes > 20000:
            sendKinesis = 1

        # approval to send the data
        if sendKinesis == 1:
            
            # adding the data to kinesis
            response = client.put_records(
                Records=combine_rows,
                StreamName = stream_name
            )
            print(combine_rows)
            
            #resetting the values
            combine_rows = [] 
            sendKinesis = 0 
            C_bytes = 0
            
            # Incrementing the shard counter
            shard_counter += 1
        
            
            # If reached max, reset it to 1
            if shard_counter > shard_count:
                shard_counter = 1

            # If the response is not 200, print the error
            if response['ResponseMetadata']['HTTPStatusCode'] != 200:
            	print('Error!')
               
                      

            
        # Incrementing the row counter
        rc += 1
        print(rc)
    
    
    print('Total Records sent to Kinesis: {0}'.format(len_rows))


def main():
    
    # Start time
    start = datetime.now()
    
    # setting the client
    kinesis = gen_client('kinesis','us-east-1')
    
    #Reading the data
    data = get_data('/content/Comp_data-2.csv','csv')
    
    send_kinesis(kinesis, "raw_data_stream", 1, data) 
    
    # End time
    end = datetime.now()

    #Calculating the final time
    final_time = (end - start).total_seconds() * 10**3
    
    print("Runtime: " + str(final_time))
    

    
main()

